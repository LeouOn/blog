---
title: "First Post"
date: 2019-03-28
lastmod:
draft: false
tags: ["blog", "plan"]
categories: ["blog"]

menu:
main:
parent: "docs"
weight: 2

---



# Introduction

Welcome to a site constructed in order to keep me accountable for learning Data Science and sharing my path, with all of its struggles and hopefully benefits with the world. It is also a place for me to keep an informal portfolio of different projects that I am working on and share that with people who may be interested. 

## Goals & Plan

Generally the plan of this site is to post at least once a week, if not more often about whatever I am currently working on. The goal is that throughout the next few years, I would like to pick up enough competency in Big Data and Machine Learning to be a data scientist. I am not coming from square one since I already have programming skills in SQL, Python, and R with enough experience to have a solid foundation. I however would like to take my skills to the next level so I can easily demonstrate my skills and ability.

### Data Science Path 
Inspired by [Udacity's Data Career Skills Checklist](https://blog.udacity.com/data-analyst-skills-checklist-eguide)
#### Computer Science / Machine Learning
##### Software Skills
- [x] Unix Command Line
- [x] Version Control with Git
- [x] Vim / Spacemacs

##### Foundational Programming

###### Python ######

- [x] Learn Numpy
- [x] Learn Pandas
- [x] String Manipulations
- [x] Reading and writing
- [x] Regex (Regular Expressions)
- [x] Mathematical Transformations
- [x] Functional Programming
- [x] Plotting with Matplotlib
- [x] Seaborne Visualization
- [x] Pairplotting
- [x] Anaconda / iPython
- [x] Data Cleaning with Python
- [x] Flask
- [x] SQLAlchemy
- [ ] SciPy
- [ ] Master Scikit-learn
- [x] REST Functionality (GET/POST/PUT/DELETE)

######  R ######

- [x] GGPlot
- [x] Linear Modeling
- [x] Dplyr
- [x] Tidyr
- [x] Readr
- [x] Reshape1
-

###### SQL ######

- [x] Querying
- [x] Merge, Union, Slicing
- [x] Aggregation
- [x] Conditionals
- [x] Updating and Writing Database

##### Machine Learning

###### Supervised Learning
- [ ] Decision Trees
- [x] Naive Bayes Classification
- [x] Ordinary Least Squares (OLS) regression
- [x] Logistic regression
- [ ] Support Vector Machines (SVMs)
- [ ] Ensemble Methods

###### Unsupervised Learning
- [x] Random Forest Clustering
- [x] K-means Clustering
- [x] Principal Component Analysis (PCA)
- [ ] Singular Value Decomposition (SVD)

###### Reinforcement Learning
- [ ] Q-Learning
- [ ] TD-Learning
- [ ] Genetic Algorithms

###### Deep Learning

- [ ] Neural Networks
- [ ] Convolutional Neural Networks
- [ ] Recurrent Neural Networks
- [ ] Generative Adversarial Networks
- [ ] TensorFlow v2

###### Computer Vision

###### Applied ML ######
- [ ] Content Analysis
- [ ] Personality Traits
- [ ] Word2Vec
- [ ] CosineSimilarity

###### General AI ######
- [ ] Graduate Introduction to AI

##### Big Data
- [ ] Cisco Spark
- [x] Docker Containers
- [ ] Kubernetes
- [ ] Pachyderm 
- [ ] Hadoop
- [ ] CS229r Algorithms for Big Data

##### CS Curriculum #####

###### Computer Systems and Architecture ######
- [ ] CMU Intro to Computer Systems
- [ ] Knuth MMIXware
- [ ] Harchol-Balter Performance Modeling and Design of Computer Systems

###### Networks ######

#### Mathematics and Statistics
##### Calculus
- [x] Derivative Calculus
- [x] Integral Calculus 

###### Multivariate Calculus

##### Linear Algebra
- [ ] Matrix Manipulations
- [ ] Dot Product
- [ ] Eigenvalues
- [ ] Eigenvectors

##### Statistics

###### Descriptive Statistics

- [x] Summary Stats
- [x] Data Distributions
- [x] Standard Deviation and Variance

###### Inferential Statistics

- [x] Hypothesis Testing w/ Significance Intervals
- [x] Significance Testing
- [x] Chi-squared and ANOVA testing
- [x] Linear Regression
- [x] Logistic REgression

###### Discrete Mathematics ######
- [ ] Read An Infinite Descent into Pure Mathematics
- [ ] Discrete Mathmatics and Functional Programming - Thomas VanDrunen
- [ ] Watch Great Theoretical Ideas in Computer Science 
#### Substantive Skills

##### Experiment Design

- [x] A/B Testing
- [ ] Multiarmed Bandit (Intelligent A/B Testing)
- [x] Variable Control
- [x] Sample Size and Power Law
- [x] Confidence level
- [ ] Bayesian Statistics
- [ ] Bootstrapping
- [ ] Simulation

##### Econometrics 

### Schedule of Plan ###
Making and checking off this checklist gives me an idea that I already have a pretty good grounding and foundation for data science. What I need to work on is 1-2 weeks review periodically to keep my skills fresh and on recall. Having periodic reinforcement will be essential to retaining this knowledge over time. I have recognized that it is hard to keep knowledge fresh, already I have forgetten so much physics and chemistry from my undergraduate studies! Since I deeply care about getting involved in Machine Learning and Data Science it only makes sense for me to keep the important information fresh over time in such a way that the 20% of information that make up 80% of the work will be second nature to me. If I am also aware of the 80% that compose the remaining 20% then I should also learn where I can get that information from as needed. Of course, as an amateur practicioner I am not going to immediately know which 20% I have to learn! 

(Insert image about learning and periodic reinforcement)

I am going to use the Agile Sprint model to keep myself accountable. This involves 2 week 'sprints' with retrospectives.
#### Spring 2019 ####
Weeks 1-2: Review
For the first week I am going to settle in and post a review about what I know. I am going to try to watch 5-6 hours of video at 2x speed and speed read books so that I can comprehensively learn the basics. I will take a few org-mode notes and post them up here as my Week 1 Recap.
The most important aspect is getting the schedule and discipline to keep on working day after day. I shall not give up on my practice and learning. Additionally I will try to build the basic structure of the afflictive emotions quiz which is good practice for the dynamic site that I want to implement. Of course this can be difficult since github pages is optimized for static pages but I will work to set up some routes and API calls to firebase. 
The second week I will work on consolidating that information and learning where I need to tackle further. One of the first projects I should work on is my second year paper looking into the connection between industry money and speech content in the House of Representatives. This will be the first and most important field I need to approach since it is directly related to my doctoral progress. 

Weeks 3-4: Second Year Paper Progress
This week I will attempt to get preliminary results for my second year paper. I will identify 10 representatives that receive the most money from industries that seem to be highly related 
I will work on drafting the literature review and describing my results. After this I will send to my second year paper readers - Professors Priscilla Southwell and Mikhail Myagkov. 

Weeks 5-6: Big Data
Big Data is important for my potential dissertation topic focusing on social network datasets. 
If I am approved by Social Science One to analyze the Facebook dataset, I will need to build a data pipeline using Apache Spark, Docker Containers, and Kubernetes Clusters to process the data into meaningful information. 
The best way to learn is to learn by doing and then teach it, so I will post _anonymized_ data about my process and what I am doing so others can follow along. I am really excited about the opportunity to conduct research that is both meaningful and will give me the capacity to deal with this large dataset. 
Information is getting bigger and bigger, having these large sets gives our results both statistical power as well as reveals many unique distinct aspects. 

Weeks 7-8: Deep Learning
 
Weeks 9-10: Finish Projects.

#### Summer 2019 ####

Early Summer - ICPSR (Potentially)
I have another exciting opportunity to study Machine Learning at the University of Michigan. I will post the information that I am learning and accumulating over time. I think after the 5 sprints of foundational work that I am laying for myself during Spring 2019 I will be in a good position to do some innovative work during the summer. Hopefully I will make the final touches on my second year paper and then I will start work on my Facebook dissertation project. 

It is always possible to plan further out into the future but I think this will be a good basis to start off with. As mentioned in the checklist, it would be nice for me to develop more core Computer Science skills as needed. I think the most important core skills for data science would be algorithms and data structures. This is especially important for the big data dissertation project since computational power and storage will be at a premium! 

Now that I have a semi-solid plan the most important next step is the execution. Without the execution, the best laid plans and dreams are just that -- dreams. 
